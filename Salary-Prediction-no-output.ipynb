{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a project aimed for predicting future salaries of job postings based on salaries of current job postings. The language of choice to tackle this problem is Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "__author__ = \"Lukas Barbuscak\"\n",
    "__email__ = \"lukas.barbuscak@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading the data\n",
    "df_features = pd.read_csv(\"data\\\\train_features.csv\")\n",
    "df_salaries = pd.read_csv(\"data\\\\train_salaries.csv\")\n",
    "df_test = pd.read_csv(\"data\\\\test_features.csv\")\n",
    "\n",
    "#merging the features and salaries datasets based on JobId\n",
    "df = pd.merge(df_features, df_salaries, on=\"jobId\")\n",
    "\n",
    "#releasing memory\n",
    "del df_features, df_salaries\n",
    "\n",
    "#examining the dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the dataset looks very clean. Numeric values are stored as floats and string values are stored as objects. Let's check for any possible irregularities in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#checking for the total number of missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking if missing values are encoded as \"0\"\n",
    "df.eq(0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume that 0 in years of experience is not a sign of missing values, since someone can have experience less than 1 year. I also assume that miles from Metropolis being 0 is not an issue, since being from Metropolis means distance to Metropolis would indeed be 0. However, salary being 0 either indicates a missing value, or volunteering, and that is not relevant for the model. I will drop the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping observations which have salary as 0\n",
    "df.drop(df[df.salary == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking for possible irregularities for object dtypes\n",
    "print(\"Job type values:\", df.jobType.unique())\n",
    "print(\"Degree values:\", df.degree.unique())\n",
    "print(\"Major values:\", df.major.unique())\n",
    "print(\"Industry values:\", df.industry.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for possible irregularities for numeric dtypes\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be no issues with the first two columns, but salary might have possible outliers. Let's check this using a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating a box plot\n",
    "df.boxplot(column=[\"salary\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking the percentage of outliers\n",
    "salary_outliers = np.sum(df[\"salary\"]>=210)\n",
    "print(\"The percentage of outliers is:\", salary_outliers/df[\"salary\"].count()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the percentage is relatively large and they do not appear to be errors, I will keep the outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicate Job ID values\n",
    "df_no_duplicates = df.drop('jobId', axis=1).drop_duplicates()\n",
    "print(df.shape)\n",
    "print(df_no_duplicates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the changes to the original dataset\n",
    "df = df_no_duplicates\n",
    "print(df.shape)\n",
    "\n",
    "del df_no_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the differences between groups, and plotting them if necessary\n",
    "companyId_summary=df.groupby(\"companyId\")\n",
    "companyId_summary.mean().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_summary = df.groupby(\"degree\")\n",
    "degree_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "sns.boxplot(x=df[\"degree\"],y=df[\"salary\"], \n",
    "            palette=(\"GnBu_d\"), order=[\"DOCTORAL\",\"MASTERS\",\"BACHELORS\",\"HIGH_SCHOOL\",\"NONE\"])\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobType_summary = df.groupby(\"jobType\")\n",
    "jobType_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "sns.boxplot(x=df[\"jobType\"],y=df[\"salary\"], \n",
    "            palette=(\"GnBu_d\"), order=[\"CEO\",\"CTO\",\"CFO\",\"VICE_PRESIDENT\",\"MANAGER\",\"SENIOR\",\"JUNIOR\",\"JANITOR\"])\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.xlabel(\"Job Type\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_summary = df.groupby(\"major\")\n",
    "major_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "industry_summary = df.groupby(\"industry\")\n",
    "industry_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "sns.boxplot(x=df[\"industry\"],y=df[\"salary\"], palette=(\"GnBu_d\"),\n",
    "           order=[\"OIL\",\"FINANCE\",\"WEB\",\"HEALTH\",\"AUTO\",\"SERVICE\",\"EDUCATION\"])\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.xlabel(\"Industry\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, all categorical variables show no mean differences between the categories and years of experience, or number of miles from Metropolis. The only differences in general seem to be in differences in salary.\n",
    "\n",
    "We can see there is a difference between observations with high school/no education, and observations with master's/doctoral/bachelor's degrees, which have slight differences between each other as well. The job type bar graph does not say anything surprising about the data again, CEO observations have the highest salary, and janitor observations have the lowest. The mean differences between the majors are minimal, with the only significant visible difference is having a major or not having a major. There are differences between industries, with oil and finance being the with the highest mean, and service and education the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#creating a countplot for each categorical variable presented as a subplot\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(5, 1, figsize=(15, 20))\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
    "ax = fig.add_subplot(5, 1, 1)\n",
    "sns.countplot(df['companyId'])\n",
    "ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "plt.xlabel(\"Company ID\")\n",
    "ax = fig.add_subplot(5, 1, 2)\n",
    "sns.countplot(df['jobType'])\n",
    "plt.xlabel(\"Job Type\")\n",
    "ax = fig.add_subplot(5, 1, 3)\n",
    "sns.countplot(df['major'])\n",
    "plt.xlabel(\"Major\")\n",
    "ax = fig.add_subplot(5, 1, 4)\n",
    "sns.countplot(df['industry'])\n",
    "plt.xlabel(\"Industry\")\n",
    "ax = fig.add_subplot(5, 1, 5)\n",
    "sns.countplot(df['degree'])\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.subplots_adjust(top = 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset seems extremely balanced in terms of distribution of each categorical variable: the job type count is roughly the same for all job types, there is only slightly more people with no major/without post-secondary education in the dataset than their counterparts, and all industries and companies are represented roughly equally. This is a good sample in no need for applying any resampling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a group of numerical variables\n",
    "num = df.select_dtypes(include=[np.int64])\n",
    "\n",
    "#distribution of numerical variables\n",
    "num.hist(bins=50, figsize=(15, 6), layout=(2, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This compact representation of distribution of the numerical variables shows some valuable information. The distance from Metropolis seems very similar for all the observations, and shows a uniform distribution. The salary graph shows slight skewness to the right, but the shape overall follows normal distribution. The years of experience variable shows again a uniform shape. This is explained by good sampling, and again, there is no need for any resampling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#drawing lineplots\n",
    "sns.lineplot(x=df['yearsExperience'], y=df['salary'], data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(x=df['milesFromMetropolis'], y=df['salary'], data=df, color=\"red\")\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(x=df['milesFromMetropolis'], y=df['yearsExperience'], data=df, color=\"yellow\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graphs, we can see that salaries generally decrease with larger distance from Metropolis. Also, salaries tend to increase with years of experience in general. There does not seem to be a relationship between years of experience and miles from Metropolis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#creating a correlation heatmap and a correlation table\n",
    "sns.heatmap(df.corr())\n",
    "plt.show()\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is a positive correlation between years of experience and salary, and a slight negative correlation between miles from Metropolis and salary. There is no correlation between years of experience and miles from Metropolis.\n",
    "\n",
    "The EDA has shown valuable information: I am dealing with a balanced dataset, and the relationship between the dependent variable and the predictors seems to be linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a regression problem with the dependent variable being a continuous one, MSE is a simple and fitting choice to use it as a metric for my model. As my baseline model, I will use difference from average salary, since every ML model should be able to outperform differences from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummies, appending them to the original dataset, and dropping the original columns\n",
    "dummy_1 = pd.get_dummies(df[\"jobType\"])\n",
    "df = pd.concat([df, dummy_1], axis=1)\n",
    "df.drop(\"jobType\", axis = 1, inplace=True)\n",
    "\n",
    "dummy_2 = pd.get_dummies(df[\"industry\"])\n",
    "df = pd.concat([df, dummy_2], axis=1)\n",
    "df.drop(\"industry\", axis = 1, inplace=True)\n",
    "\n",
    "dummy_3 = pd.get_dummies(df[\"degree\"], prefix='degree')\n",
    "df = pd.concat([df, dummy_3], axis=1)\n",
    "df.drop(\"degree\", axis = 1, inplace=True)\n",
    "\n",
    "dummy_4 = pd.get_dummies(df[\"major\"], prefix='major')\n",
    "df = pd.concat([df, dummy_4], axis=1)\n",
    "df.drop(\"major\", axis = 1, inplace=True)\n",
    "\n",
    "dummy_5 = pd.get_dummies(df[\"companyId\"])\n",
    "df = pd.concat([df, dummy_5], axis=1)\n",
    "df.drop(\"companyId\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dataset only containing \"salary\"\n",
    "target = df[\"salary\"]\n",
    "\n",
    "#creating a baseline model, using just average, manually computing MSE\n",
    "target_mean = target.mean()\n",
    "df[\"salary_pred\"]= target_mean\n",
    "df[\"salary_dif\"]=df[\"salary\"]-df[\"salary_pred\"]\n",
    "df[\"salary_dif_squared\"]=df[\"salary_dif\"]**2\n",
    "df[\"salary_sum\"]=df[\"salary_dif_squared\"].sum()\n",
    "df[\"salary_MSE\"]=df[\"salary_sum\"]/df[\"salary_sum\"].count()\n",
    "print(\"The MSE of the model using just means is:\", df[\"salary_MSE\"][0])\n",
    "\n",
    "#dropping the variables from the dataset\n",
    "df.drop([\"salary\",\"salary_pred\",\"salary_dif\",\"salary_dif_squared\",\"salary_sum\",\"salary_MSE\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE from my simple model using only means is very high, I need to come up with models that will improve the MSE. My models of choice are:\n",
    "\n",
    "- Linear Regression: as seen in the EDA, our data follows a relatively linear shape\n",
    "- Decision Trees: just like linear regression, it is a basic and fast approach for modeling, and performs well with linear relationships\n",
    "- Gradient Boosting: because this is a regression problem, gradient boosting offers great way for weak learners to improve their performance, and is often used to minimize the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEVELOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating MSE for Linear Regression\n",
    "\n",
    "#importing packages\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#fitting the model\n",
    "lm = LinearRegression()\n",
    "lm.fit(df,target)\n",
    "\n",
    "#measuring MSE during 5-fold cross-validation and printing the result\n",
    "lm_scores = cross_val_score(lm,df,target,scoring=\"neg_mean_squared_error\")\n",
    "lm_mse = -1*lm_scores.mean()\n",
    "print(\"The average MSE of the linear regression:\", lm_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating MSE for Decision Trees, repeating the process\n",
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeRegressor()\n",
    "dt.fit(df,target)\n",
    "\n",
    "dt_scores = cross_val_score(dt,df,target,scoring=\"neg_mean_squared_error\")\n",
    "dt_mse = -1*dt_scores.mean()\n",
    "print(\"Average MSE of the decision tree model:\", dt_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating MSE for Gradient Boosting, repeating the process\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=150, max_depth=5)\n",
    "gb.fit(df,target)\n",
    "\n",
    "gb_scores = cross_val_score(gb,df,target,scoring=\"neg_mean_squared_error\")\n",
    "gb_mse = -1*gb_scores.mean()\n",
    "print(\"Average MSE of the gradient boosting model:\", gb_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest average MSE has been reached by the gradient boosting model. I will use this result to score the test dataset, and analyze which features are the most important for the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset\n",
    "#this means starting from the beginning entirely, and simplify the code written\n",
    "\n",
    "#saving the gradient boosting model\n",
    "import joblib\n",
    "joblib_file = \"GB_salary_model.pkl\"\n",
    "joblib.dump(gb, joblib_file)\n",
    "\n",
    "#loading the saved model\n",
    "model = joblib.load(\"GB_salary_model.pkl\")\n",
    "print(\"The model used is:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing the test dataset\n",
    "df_test_no_duplicates = df_test.drop('jobId', axis=1).drop_duplicates()\n",
    "df_test = df_test_no_duplicates\n",
    "del df_test_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummies\n",
    "dummy_test_1 = pd.get_dummies(df_test[\"jobType\"])\n",
    "df_test = pd.concat([df_test, dummy_test_1], axis=1)\n",
    "df_test.drop(\"jobType\", axis = 1, inplace=True)\n",
    "\n",
    "dummy_test_2 = pd.get_dummies(df_test[\"industry\"])\n",
    "df_test = pd.concat([df_test, dummy_test_2], axis=1)\n",
    "df_test.drop(\"industry\", axis = 1, inplace=True)\n",
    "\n",
    "dummy_test_3 = pd.get_dummies(df_test[\"degree\"], prefix=\"degree\")\n",
    "df_test = pd.concat([df_test, dummy_test_3], axis=1)\n",
    "df_test.drop(\"degree\", axis = 1, inplace=True)\n",
    "\n",
    "dummy_test_4 = pd.get_dummies(df_test[\"major\"], prefix=\"major\")\n",
    "df_test = pd.concat([df_test, dummy_test_4], axis=1)\n",
    "df_test.drop(\"major\", axis = 1, inplace=True)\n",
    "\n",
    "dummy_test_5 = pd.get_dummies(df_test[\"companyId\"])\n",
    "df_test = pd.concat([df_test, dummy_test_5], axis=1)\n",
    "df_test.drop(\"companyId\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring the test dataset\n",
    "salary_predictions = model.predict(df_test)\n",
    "\n",
    "#saving the predictions\n",
    "np.savetxt('salary_predictions.csv', salary_predictions, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing feature importances\n",
    "importances = pd.Series(model.feature_importances_, index=df.columns)\n",
    "importances.nlargest(10).plot(kind='bar', figsize=(12,6))\n",
    "plt.show()\n",
    "\n",
    "#saving feature importances\n",
    "np.savetxt('salary_importances.csv', importances, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have developed a model that is predicting future salaries of job postings based on salaries of current job postings. After performing the exploratory data analysis, I  fitted three models and compared their mean squared errors, basically comparing how well the models performed comparing to the baseline model, and also each other. The model performing the best with the train data was the gradient boosting model. I saved the model, scored the test data with it, and saved the results of the prediction in a csv file. I also included the analysis of feature importances, and saved it in a separate file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
